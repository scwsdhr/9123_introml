
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{lab06\_emnist\_partial}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \hypertarget{lab-6-svms-on-extended-mnist}{%
\section{Lab 6: SVMs on Extended
MNIST}\label{lab-6-svms-on-extended-mnist}}

In the \href{demo06_mnist_svm.ipynb}{MNIST demo}, we saw how SVMs can be
used for the classic MNIST problem of digit recognition. In this lab, we
are going to extend the MNIST dataset by adding a number of non-digit
letters and see if the classifier can distinguish the digits from the
non-digits. All non-digits will be lumped as a single 11-th class. This
is a highly simplified version of `detection' problem (as opposed to
`classification' problem). Detection is vital in OCR and related
problems since the non useful characters must be rejected.

In addition to the concepts in the demo, you will learn: * Combine
multiple datasets * Select the SVM parameters (\texttt{C} and
\texttt{gamma}) via cross-validation. * Use the \texttt{GridSearchCV}
method to search for parameters with cross-validation.

Note: An {[}earlier version{]}(lab06\_emnist\_ of this lab made you
manually create the combined letter and digit data. In this lab, we will
download the data from NIST website. But, the old lab is still useful to
look at if you want to see how to use \texttt{skimage} package for a
number of image pre-processing tasks.

    As usual, we download the standard packages

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}1}]:} \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
        \PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline
        \PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k}{import} \PY{n}{linear\PYZus{}model}\PY{p}{,} \PY{n}{preprocessing}
\end{Verbatim}


    \hypertarget{downloading-the-emnist-dataset}{%
\subsection{Downloading the EMNIST
Dataset}\label{downloading-the-emnist-dataset}}

After creating the highly popular MNIST dataset, NIST created an
extended version of the dataset to include letters and digits. The
extended datase (called EMNIST) also has many more examples per class.

To download the data, first go to the
\href{https://www.nist.gov/itl/iad/image-group/emnist-dataset}{EMNIST
webpage}. Near the bottom, you will see a link for
\texttt{MATLAB\ format\ dataset}. If you click on this link, you will
download a \texttt{zip} file with several datasets in it. The total file
is 726M, so it may take some time and diskspace to download. Extract two
files: * \texttt{emnist-digits.mat}: This is a file of digits \texttt{0}
to \texttt{9}, but with more examples per class. *
\texttt{emnist-letters.mat}: This is a file of letters \texttt{a/A} to
\texttt{z/Z}. The lower and upper case letters are grouped into the same
class.

Once you get these two files, you can save yourself the diskspace and
remove all the other files.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}2}]:} \PY{c+c1}{\PYZsh{} TODO:  Download emnist\PYZhy{}letters.mat and emnist\PYZhy{}digits.mat to the working directory}
\end{Verbatim}


    Since MATLAB files are still widely-used, Python has excellent routines
for loading MATLAB files. The function below uses the \texttt{scipy.io}
package to extract the relevant fields from the MATLAB file.
Specifically, the function extracts the training and test data from
MATLAB file.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}3}]:} \PY{k+kn}{import} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{io}
        \PY{k}{def} \PY{n+nf}{load\PYZus{}emnist}\PY{p}{(}\PY{n}{file\PYZus{}path}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{emnist\PYZhy{}digits.mat}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
        \PY{l+s+sd}{    Loads training and test data with ntr and nts training and test samples}
        \PY{l+s+sd}{    The `file\PYZus{}path` is the location of the `eminst\PYZhy{}balanced.mat`.}
        \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}    
            
            \PY{c+c1}{\PYZsh{} Load the MATLAB file}
            \PY{n}{mat} \PY{o}{=} \PY{n}{scipy}\PY{o}{.}\PY{n}{io}\PY{o}{.}\PY{n}{loadmat}\PY{p}{(}\PY{n}{file\PYZus{}path}\PY{p}{)}
            
            \PY{c+c1}{\PYZsh{} Get the training data}
            \PY{n}{Xtr} \PY{o}{=} \PY{n}{mat}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dataset}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{[}\PY{p}{:}\PY{p}{]}
            \PY{n}{ntr} \PY{o}{=} \PY{n}{Xtr}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
            \PY{n}{ytr} \PY{o}{=} \PY{n}{mat}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dataset}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{[}\PY{p}{:}\PY{p}{]}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{n}{ntr}\PY{p}{)}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{n+nb}{int}\PY{p}{)}
            
            \PY{c+c1}{\PYZsh{} Get the test data}
            \PY{n}{Xts} \PY{o}{=} \PY{n}{mat}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dataset}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{[}\PY{p}{:}\PY{p}{]}
            \PY{n}{nts} \PY{o}{=} \PY{n}{Xts}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
            \PY{n}{yts} \PY{o}{=} \PY{n}{mat}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dataset}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{[}\PY{p}{:}\PY{p}{]}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{n}{nts}\PY{p}{)}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{n+nb}{int}\PY{p}{)}
            
            \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+si}{\PYZpc{}d}\PY{l+s+s2}{ training samples, }\PY{l+s+si}{\PYZpc{}d}\PY{l+s+s2}{ test samples loaded}\PY{l+s+s2}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{p}{(}\PY{n}{ntr}\PY{p}{,} \PY{n}{nts}\PY{p}{)}\PY{p}{)}
        
            \PY{k}{return} \PY{p}{[}\PY{n}{Xtr}\PY{p}{,} \PY{n}{Xts}\PY{p}{,} \PY{n}{ytr}\PY{p}{,} \PY{n}{yts}\PY{p}{]}
\end{Verbatim}


    Use the function above to get all the digit images from the
\texttt{emnist-digits.mat} file.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{c+c1}{\PYZsh{} TODO:  Load the digit data from emnist\PYZhy{}digits.mat}
        \PY{n}{Xtr\PYZus{}dig}\PY{p}{,} \PY{n}{Xts\PYZus{}dig}\PY{p}{,} \PY{n}{ytr\PYZus{}dig}\PY{p}{,} \PY{n}{yts\PYZus{}dig} \PY{o}{=} \PY{n}{load\PYZus{}emnist}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{emnist\PYZhy{}digits.mat}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
240000 training samples, 40000 test samples loaded

    \end{Verbatim}

    Next, use the function above to get all the letter characters from the
\texttt{emnist-letters.mat} file.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}5}]:} \PY{c+c1}{\PYZsh{} TODO:  Load the digit data from emnist\PYZhy{}letters.mat}
        \PY{n}{Xtr\PYZus{}let}\PY{p}{,} \PY{n}{Xts\PYZus{}let}\PY{p}{,} \PY{n}{ytr\PYZus{}let}\PY{p}{,} \PY{n}{yts\PYZus{}let} \PY{o}{=} \PY{n}{load\PYZus{}emnist}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{emnist\PYZhy{}letters.mat}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
124800 training samples, 20800 test samples loaded

    \end{Verbatim}

    We will use the function from the demo to plot the digits.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}6}]:} \PY{k}{def} \PY{n+nf}{plt\PYZus{}digit}\PY{p}{(}\PY{n}{x}\PY{p}{,}\PY{n}{y}\PY{o}{=}\PY{k+kc}{None}\PY{p}{)}\PY{p}{:}
            \PY{n}{nrow} \PY{o}{=} \PY{l+m+mi}{28}
            \PY{n}{ncol} \PY{o}{=} \PY{l+m+mi}{28}
            \PY{n}{xsq} \PY{o}{=} \PY{n}{x}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{p}{(}\PY{n}{nrow}\PY{p}{,}\PY{n}{ncol}\PY{p}{)}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{xsq}\PY{o}{.}\PY{n}{T}\PY{p}{,}  \PY{n}{cmap}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Greys\PYZus{}r}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{p}{[}\PY{p}{]}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{yticks}\PY{p}{(}\PY{p}{[}\PY{p}{]}\PY{p}{)}    
            \PY{k}{if} \PY{n}{y} \PY{o}{!=} \PY{k+kc}{None}\PY{p}{:}
                \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZpc{}d}\PY{l+s+s1}{\PYZsq{}} \PY{o}{\PYZpc{}} \PY{n}{y}\PY{p}{)}        
\end{Verbatim}


    Plot 8 random samples from the digit training data. You can use the
\texttt{plt\_digit} function above with \texttt{subplot} to create a
nice display. You may want to size your plot with the
\texttt{plt.figure(figsize=(10,20))} command.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}7}]:} \PY{c+c1}{\PYZsh{} TODO:  Plot 8 random samples from the training data of the digits}
        \PY{k+kn}{import} \PY{n+nn}{random}
        \PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{p}{)}
        \PY{n}{rnd} \PY{o}{=} \PY{n}{random}\PY{o}{.}\PY{n}{sample}\PY{p}{(}\PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{ytr\PYZus{}dig}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{l+m+mi}{8}\PY{p}{)}
        \PY{n}{nplt} \PY{o}{=} \PY{l+m+mi}{8}
        \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{,}\PY{l+m+mi}{20}\PY{p}{)}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Label:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{ytr\PYZus{}dig}\PY{p}{[}\PY{n}{rnd}\PY{p}{]}\PY{p}{)}
        \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{nplt}\PY{p}{)}\PY{p}{:}
            \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{nplt}\PY{p}{,} \PY{n}{i}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}
            \PY{n}{plt\PYZus{}digit}\PY{p}{(}\PY{n}{Xtr\PYZus{}dig}\PY{p}{[}\PY{n}{rnd}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Label: [4 4 8 2 1 4 4 0]

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_14_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Next, plot 8 samples from the letters training data. You should see that
the labels go from 0 to 25 corresponding to \texttt{a} to \texttt{z}.
Upper and lower case letters belong to the same class.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}8}]:} \PY{c+c1}{\PYZsh{} TODO:  Plot 8 random samples from the training data of the letters}
        \PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{p}{)}
        \PY{n}{rnd} \PY{o}{=} \PY{n}{random}\PY{o}{.}\PY{n}{sample}\PY{p}{(}\PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{ytr\PYZus{}let}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{l+m+mi}{8}\PY{p}{)}
        \PY{n}{nplt} \PY{o}{=} \PY{l+m+mi}{8}
        \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{,}\PY{l+m+mi}{20}\PY{p}{)}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Label:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{ytr\PYZus{}let}\PY{p}{[}\PY{n}{rnd}\PY{p}{]}\PY{p}{)}
        \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{nplt}\PY{p}{)}\PY{p}{:}
            \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{nplt}\PY{p}{,} \PY{n}{i}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}
            \PY{n}{plt\PYZus{}digit}\PY{p}{(}\PY{n}{Xtr\PYZus{}let}\PY{p}{[}\PY{n}{rnd}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Label: [ 9 22 21 13 25 23 21 22]

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_16_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \hypertarget{creating-a-non-digit-class}{%
\subsection{Creating a Non-Digit
Class}\label{creating-a-non-digit-class}}

SVM classifiers are VERY SLOW to train. The training is particularly
slow when there are a large number of classes, since the one classifier
must be trained for each pair of labels. To make the problem easier, we
are going to lump all of the letters in one class and add that class to
the digits.

Before we begin, we first need to remove all the letters corresponding
to \texttt{i/I}, \texttt{l/L} and \texttt{o/O}. The reason is that these
letters would get confused with the digits \texttt{0} and \texttt{1}.
Create arrays \texttt{Xtr\_let\_rem} and \texttt{ytr\_let\_rem} from the
data \texttt{Xtr\_let} and \texttt{ytr\_let}, where the samples
\texttt{i} with \texttt{ytr\_let{[}i{]}\ ==\ 9,\ 12} or \texttt{15} are
removed. Create \texttt{Xts\_let\_rem} and \texttt{yts\_let\_rem}
similarly.

If you are clever, you can do this without a for-loop via python
broadcasting and \texttt{np.all(...,\ axis=1)} command. But, you will
receive full marks if you use a \texttt{for-loop}.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}9}]:} \PY{n}{remove\PYZus{}list} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{9}\PY{p}{,}\PY{l+m+mi}{12}\PY{p}{,}\PY{l+m+mi}{15}\PY{p}{]}\PY{p}{)}
        \PY{n}{ftr} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{all}\PY{p}{(}\PY{n}{ytr\PYZus{}let}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{n}{remove\PYZus{}list}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
        \PY{n}{fts} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{all}\PY{p}{(}\PY{n}{yts\PYZus{}let}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{n}{remove\PYZus{}list}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} TODO:  Create arrays with labels 9, 12 and 15 removed}
        \PY{n}{Xtr\PYZus{}let\PYZus{}rem}\PY{p}{,} \PY{n}{ytr\PYZus{}let\PYZus{}rem} \PY{o}{=} \PY{n}{Xtr\PYZus{}let}\PY{p}{[}\PY{n}{ftr}\PY{p}{]}\PY{p}{,} \PY{n}{ytr\PYZus{}let}\PY{p}{[}\PY{n}{ftr}\PY{p}{]}
        \PY{n}{Xts\PYZus{}let\PYZus{}rem}\PY{p}{,} \PY{n}{yts\PYZus{}let\PYZus{}rem} \PY{o}{=} \PY{n}{Xts\PYZus{}let}\PY{p}{[}\PY{n}{fts}\PY{p}{]}\PY{p}{,} \PY{n}{yts\PYZus{}let}\PY{p}{[}\PY{n}{fts}\PY{p}{]}
\end{Verbatim}


    Since training and testing an SVM is VERY SLOW, we will use only a small
subset of the training and test data. Of course, you will not get great
results with this small dataset. But, we can at least illustrate the
basic concepts.

Create arrays \texttt{Xtr1\_dig} and \texttt{ytr1\_dig} by selecting
5000 random training digit samples from \texttt{Xtr\_dig} and
\texttt{ytr\_dig}. Create arrays \texttt{Xtr1\_let} and
\texttt{ytr1\_let} by selecting 1000 random training letter samples from
\texttt{Xtr\_let\_rem} and \texttt{ytr\_let\_rem}. Similarly, create
test arrays \texttt{Xts1\_dig,Xts1\_let,yts1\_dig,yts1\_let} with 5000
digits and 1000 letters.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}10}]:} \PY{c+c1}{\PYZsh{} Number of training and test digits and letters}
         \PY{n}{ntr\PYZus{}dig} \PY{o}{=} \PY{l+m+mi}{5000}
         \PY{n}{ntr\PYZus{}let} \PY{o}{=} \PY{l+m+mi}{1000}
         \PY{n}{nts\PYZus{}dig} \PY{o}{=} \PY{l+m+mi}{5000}
         \PY{n}{nts\PYZus{}let} \PY{o}{=} \PY{l+m+mi}{1000}
         
         \PY{c+c1}{\PYZsh{} TODO Create sub\PYZhy{}sampled training and test data}
         \PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{p}{)}
         \PY{n}{rnd} \PY{o}{=} \PY{n}{random}\PY{o}{.}\PY{n}{sample}\PY{p}{(}\PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{ytr\PYZus{}dig}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n}{ntr\PYZus{}dig}\PY{p}{)}
         \PY{n}{Xtr1\PYZus{}dig}\PY{p}{,} \PY{n}{ytr1\PYZus{}dig} \PY{o}{=} \PY{n}{Xtr\PYZus{}dig}\PY{p}{[}\PY{n}{rnd}\PY{p}{]}\PY{p}{,} \PY{n}{ytr\PYZus{}dig}\PY{p}{[}\PY{n}{rnd}\PY{p}{]}
         
         \PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{p}{)}
         \PY{n}{rnd} \PY{o}{=} \PY{n}{random}\PY{o}{.}\PY{n}{sample}\PY{p}{(}\PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{yts\PYZus{}dig}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n}{nts\PYZus{}dig}\PY{p}{)}
         \PY{n}{Xts1\PYZus{}dig}\PY{p}{,} \PY{n}{yts1\PYZus{}dig} \PY{o}{=} \PY{n}{Xts\PYZus{}dig}\PY{p}{[}\PY{n}{rnd}\PY{p}{]}\PY{p}{,} \PY{n}{yts\PYZus{}dig}\PY{p}{[}\PY{n}{rnd}\PY{p}{]}
         
         \PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{p}{)}
         \PY{n}{rnd} \PY{o}{=} \PY{n}{random}\PY{o}{.}\PY{n}{sample}\PY{p}{(}\PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{ytr\PYZus{}let\PYZus{}rem}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n}{ntr\PYZus{}let}\PY{p}{)}
         \PY{n}{Xtr1\PYZus{}let}\PY{p}{,} \PY{n}{ytr1\PYZus{}let} \PY{o}{=} \PY{n}{Xtr\PYZus{}let\PYZus{}rem}\PY{p}{[}\PY{n}{rnd}\PY{p}{]}\PY{p}{,} \PY{n}{ytr\PYZus{}let\PYZus{}rem}\PY{p}{[}\PY{n}{rnd}\PY{p}{]}
         
         \PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{p}{)}
         \PY{n}{rnd} \PY{o}{=} \PY{n}{random}\PY{o}{.}\PY{n}{sample}\PY{p}{(}\PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{yts\PYZus{}let\PYZus{}rem}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n}{nts\PYZus{}let}\PY{p}{)}
         \PY{n}{Xts1\PYZus{}let}\PY{p}{,} \PY{n}{yts1\PYZus{}let} \PY{o}{=} \PY{n}{Xts\PYZus{}let\PYZus{}rem}\PY{p}{[}\PY{n}{rnd}\PY{p}{]}\PY{p}{,} \PY{n}{yts\PYZus{}let\PYZus{}rem}\PY{p}{[}\PY{n}{rnd}\PY{p}{]}
\end{Verbatim}


    Next, we create data by combining the digit and letter arrays. * Create
an array \texttt{Xtr} by stacking \texttt{Xtr1\_dig},
\texttt{Xtr1\_let}. This should result in 6000 total samples. * Create a
new label vector \texttt{ytr} where
\texttt{ytr{[}i{]}\ =\ ytr1\_dig{[}i{]}} for any digit sample and
\texttt{ytr{[}i{]}=10} for any letter sample. Thus, all the letters are
lumped into a single class with label 11.

Create test arrays \texttt{Xts} and \texttt{yts} similarly.

You may wish to use the \texttt{np.hstack} and \texttt{np.vstack}
methods.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}11}]:} \PY{c+c1}{\PYZsh{} TODO:  Create combined letter and digit training and test data}
         \PY{n}{Xtr}\PY{p}{,} \PY{n}{ytr} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{vstack}\PY{p}{(}\PY{p}{(}\PY{n}{Xtr1\PYZus{}dig}\PY{p}{,} \PY{n}{Xtr1\PYZus{}let}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{hstack}\PY{p}{(}\PY{p}{(}\PY{n}{ytr1\PYZus{}dig}\PY{p}{,} \PY{l+m+mi}{10}\PY{o}{*}\PY{n}{np}\PY{o}{.}\PY{n}{ones}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{ytr1\PYZus{}let}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n}{Xts}\PY{p}{,} \PY{n}{yts} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{vstack}\PY{p}{(}\PY{p}{(}\PY{n}{Xts1\PYZus{}dig}\PY{p}{,} \PY{n}{Xts1\PYZus{}let}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{hstack}\PY{p}{(}\PY{p}{(}\PY{n}{yts1\PYZus{}dig}\PY{p}{,} \PY{l+m+mi}{10}\PY{o}{*}\PY{n}{np}\PY{o}{.}\PY{n}{ones}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{yts1\PYZus{}let}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    The training data above takes values from 0 to 255. Rescale the data
from -1 to 1. This will get slightly better performance on the SVM. Save
the scaled data into arrays \texttt{Xtr1} and \texttt{Xts1}.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}12}]:} \PY{c+c1}{\PYZsh{} TODO:  Rescale the data from \PYZhy{}1 to 1}
         \PY{n}{Xtr1} \PY{o}{=} \PY{n}{Xtr} \PY{o}{/} \PY{l+m+mf}{255.0} \PY{o}{*} \PY{l+m+mi}{2} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1}
         \PY{n}{Xts1} \PY{o}{=} \PY{n}{Xts} \PY{o}{/} \PY{l+m+mf}{255.0} \PY{o}{*} \PY{l+m+mi}{2} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1}
\end{Verbatim}


    \hypertarget{run-the-svm-classifier}{%
\subsection{Run the SVM classifier}\label{run-the-svm-classifier}}

First create the SVM classifer. Use an \texttt{rbf} classifier with
\texttt{C=2.8} and \texttt{gamma=.0073}. We will look at how to select
these parameters laters.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}13}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k}{import} \PY{n}{svm}
         
         \PY{c+c1}{\PYZsh{} TODO:  Create a classifier: a support vector classifier}
         \PY{n}{svc} \PY{o}{=} \PY{n}{svm}\PY{o}{.}\PY{n}{SVC}\PY{p}{(}\PY{n}{kernel}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rbf}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{C}\PY{o}{=}\PY{l+m+mf}{2.8}\PY{p}{,} \PY{n}{gamma}\PY{o}{=}\PY{o}{.}\PY{l+m+mi}{0073}\PY{p}{)}
\end{Verbatim}


    Fit the classifier using the scaled training data. SVMs are insanely
slow to train. But, in this lab, we have kept the training size very
small. So, the fitting should take about a minute or two.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}14}]:} \PY{c+c1}{\PYZsh{} TODO:  Fit the classifier on the training data. }
         \PY{n}{svc}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{Xtr1}\PY{p}{,} \PY{n}{ytr}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}14}]:} SVC(C=2.8, cache\_size=200, class\_weight=None, coef0=0.0,
           decision\_function\_shape='ovr', degree=3, gamma=0.0073, kernel='rbf',
           max\_iter=-1, probability=False, random\_state=None, shrinking=True,
           tol=0.001, verbose=False)
\end{Verbatim}
            
    Measure the accuracy on the test data. This too will take another huge
amount of time. Print the accuracy. If you did everything right, you
should get an accuracy of around 89\%.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}15}]:} \PY{c+c1}{\PYZsh{} TODO:  Measure error on the test data}
         \PY{n}{yhat\PYZus{}ts} \PY{o}{=} \PY{n}{svc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{Xts1}\PY{p}{)}
         \PY{n}{acc} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{yhat\PYZus{}ts} \PY{o}{==} \PY{n}{yts}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Accuaracy = }\PY{l+s+si}{\PYZpc{}f}\PY{l+s+s1}{\PYZsq{}} \PY{o}{\PYZpc{}} \PY{n}{acc}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Accuaracy = 0.913000

    \end{Verbatim}

    The error rate is quite a bit higher than what we got in the digits only
case. Actually, had we done a classifier using all 36 labels instead of
collapsing the letters to a single class, the SVM classifier would have
done much better. The reason is that the ``letters'' class is now
extremely complex.

Print a confusion matrix. You should see that the error rate on the
``letters'' class is much higher.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}16}]:} \PY{c+c1}{\PYZsh{} TODO:  Print a confusion matrix}
         \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics} \PY{k}{import} \PY{n}{confusion\PYZus{}matrix}
         \PY{n}{C} \PY{o}{=} \PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{yts}\PY{p}{,}\PY{n}{yhat\PYZus{}ts}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Normalize the confusion matrix}
         \PY{n}{Csum} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{n}{C}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}
         \PY{n}{C} \PY{o}{=} \PY{n}{C} \PY{o}{/} \PY{n}{Csum}\PY{p}{[}\PY{k+kc}{None}\PY{p}{,}\PY{p}{:}\PY{p}{]}
         
         \PY{c+c1}{\PYZsh{} Print the confusion matrix}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array\PYZus{}str}\PY{p}{(}\PY{n}{C}\PY{p}{,} \PY{n}{precision}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{suppress\PYZus{}small}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{C}\PY{p}{,} \PY{n}{interpolation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{none}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{colorbar}\PY{p}{(}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
[[0.95  0.    0.    0.    0.    0.    0.004 0.    0.    0.    0.024]
 [0.    0.981 0.002 0.    0.    0.    0.    0.002 0.    0.    0.008]
 [0.002 0.002 0.906 0.    0.    0.    0.    0.002 0.006 0.    0.042]
 [0.002 0.    0.008 0.936 0.    0.006 0.    0.004 0.011 0.004 0.014]
 [0.002 0.    0.    0.    0.913 0.    0.002 0.    0.002 0.014 0.034]
 [0.    0.    0.    0.006 0.    0.905 0.002 0.    0.    0.    0.041]
 [0.    0.    0.    0.    0.    0.    0.948 0.    0.    0.    0.026]
 [0.    0.    0.004 0.    0.004 0.    0.    0.96  0.002 0.    0.015]
 [0.    0.    0.002 0.008 0.    0.002 0.    0.    0.872 0.008 0.051]
 [0.    0.002 0.002 0.002 0.014 0.    0.    0.012 0.006 0.918 0.023]
 [0.038 0.021 0.039 0.019 0.04  0.078 0.028 0.01  0.025 0.041 0.831]]

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_32_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Print: * What fraction of digits are mislabeled as letters?\\
* What fraction of letters are mislabeled as digits?

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}17}]:} \PY{c+c1}{\PYZsh{} TODO:  Print above two error rates}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The fraction of digits are mislabeled as letters is }\PY{l+s+si}{\PYZpc{}.2f}\PY{l+s+si}{\PYZpc{}\PYZpc{}}\PY{l+s+s1}{.}\PY{l+s+s1}{\PYZsq{}} \PY{o}{\PYZpc{}} \PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{(}\PY{n}{yts}\PY{o}{!=}\PY{l+m+mi}{10}\PY{p}{)} \PY{o}{*} \PY{p}{(}\PY{n}{yhat\PYZus{}ts}\PY{o}{==}\PY{l+m+mi}{10}\PY{p}{)}\PY{p}{)} \PY{o}{/} \PY{n}{np}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{n}{yts}\PY{o}{!=}\PY{l+m+mi}{10}\PY{p}{)} \PY{o}{*} \PY{l+m+mi}{100}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The fraction of letters are mislabeled as digits is }\PY{l+s+si}{\PYZpc{}.2f}\PY{l+s+si}{\PYZpc{}\PYZpc{}}\PY{l+s+s1}{.}\PY{l+s+s1}{\PYZsq{}} \PY{o}{\PYZpc{}} \PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{(}\PY{n}{yts}\PY{o}{==}\PY{l+m+mi}{10}\PY{p}{)} \PY{o}{*} \PY{p}{(}\PY{n}{yhat\PYZus{}ts}\PY{o}{!=}\PY{l+m+mi}{10}\PY{p}{)}\PY{p}{)} \PY{o}{/} \PY{n}{np}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{n}{yts}\PY{o}{==}\PY{l+m+mi}{10}\PY{p}{)} \PY{o}{*} \PY{l+m+mi}{100}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
The fraction of digits are mislabeled as letters is 5.56\%.
The fraction of letters are mislabeled as digits is 16.90\%.

    \end{Verbatim}

    \hypertarget{selecting-gamma-and-c-via-cross-validation-using-for-loops}{%
\subsection{Selecting gamma and C via Cross-Validation (Using
For-Loops)}\label{selecting-gamma-and-c-via-cross-validation-using-for-loops}}

In the above example, and in the demo, we used a given \texttt{gamma}
and \texttt{C} value. The selection of the parameters depend on the
problem and decent performance of the SVM requires that you select these
parameters carefully. The best way to select the parameters is via cross
validation. Specifically, generally, one tries different values of
\texttt{gamma} and \texttt{C} and selects the pair of values the lowest
test error rate.

In the code below, we will try to use 3 values for \texttt{C} and
\texttt{gamma} as specified in the arrays \texttt{C\_test} and
\texttt{gam\_test}. For each \texttt{C} and \texttt{gamma} in these
arrays, fit a model on the training data and measure the accuracy on the
test data. Then, print the \texttt{C} and \texttt{gamma} that result in
the best accuracy.

Normally, you would try a large number of values for each of the
parameters, but an SVM is very slow to train -- even with this small
data set. So, we will just do 3 values of each. Even then, this could
take 30 minutes or so to complete.

In this lab, you may do the parameter search over \texttt{C} and
\texttt{gamma} in one of two ways: * This section: Use for loops and
manually search over the parameters. This is more direct and you will
see and control exactly what is happening. * Next section: Use the
\texttt{GridSearchCV} method in the \texttt{sklearn} package. This takes
a little reading, but once you learn this method, you can more easily
use this for complex parameter searches.

\textbf{You only need to submit the solutions to one of the two
sections.} Pick whichever one you want.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}18}]:} \PY{n}{C\PYZus{}test} \PY{o}{=} \PY{p}{[}\PY{l+m+mf}{0.1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{10}\PY{p}{]}
         \PY{n}{gam\PYZus{}test} \PY{o}{=} \PY{p}{[}\PY{l+m+mf}{0.001}\PY{p}{,}\PY{l+m+mf}{0.01}\PY{p}{,}\PY{l+m+mf}{0.1}\PY{p}{]}
         
         \PY{n}{nC} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{C\PYZus{}test}\PY{p}{)}
         \PY{n}{ngam} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{gam\PYZus{}test}\PY{p}{)}
         \PY{n}{acc} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{p}{(}\PY{n}{nC}\PY{p}{,}\PY{n}{ngam}\PY{p}{)}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} TODO:  Measure and print the accuracy for each C and gamma value.  Store the results in acc}
         \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{C\PYZus{}test}\PY{p}{)}\PY{p}{)}\PY{p}{:}
             \PY{k}{for} \PY{n}{j} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{gam\PYZus{}test}\PY{p}{)}\PY{p}{)}\PY{p}{:}
                 \PY{n}{svc} \PY{o}{=} \PY{n}{svm}\PY{o}{.}\PY{n}{SVC}\PY{p}{(}\PY{n}{kernel}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rbf}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{C}\PY{o}{=}\PY{n}{C\PYZus{}test}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{,} \PY{n}{gamma}\PY{o}{=}\PY{n}{gam\PYZus{}test}\PY{p}{[}\PY{n}{j}\PY{p}{]}\PY{p}{)}
                 \PY{n}{svc}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{Xtr1}\PY{p}{,} \PY{n}{ytr}\PY{p}{)}
                 \PY{n}{yhat\PYZus{}ts} \PY{o}{=} \PY{n}{svc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{Xts1}\PY{p}{)}
                 \PY{n}{acc}\PY{p}{[}\PY{n}{i}\PY{p}{,}\PY{n}{j}\PY{p}{]} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{yhat\PYZus{}ts} \PY{o}{==} \PY{n}{yts}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}19}]:} \PY{c+c1}{\PYZsh{} TODO:  Print the accuracy matrix}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The accuracy matrix is:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{acc}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
The accuracy matrix is:
[[0.7805     0.604      0.16666667]
 [0.86683333 0.89183333 0.21733333]
 [0.90133333 0.89883333 0.219     ]]

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}27}]:} \PY{c+c1}{\PYZsh{} TODO:  Print the maximum accuracy and the corresponding best C and gamma}
         \PY{n}{c} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{argmax}\PY{p}{(}\PY{n}{acc}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The maximum accuracy: }\PY{l+s+si}{\PYZpc{}.3f}\PY{l+s+si}{\PYZpc{}\PYZpc{}}\PY{l+s+s1}{\PYZsq{}} \PY{o}{\PYZpc{}} \PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{max}\PY{p}{(}\PY{n}{acc}\PY{p}{)}\PY{o}{*}\PY{l+m+mi}{100}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The corresponding best C and gamma: C=}\PY{l+s+si}{\PYZpc{}r}\PY{l+s+s1}{, gamma=}\PY{l+s+si}{\PYZpc{}r}\PY{l+s+s1}{\PYZsq{}} \PY{o}{\PYZpc{}} \PY{p}{(}\PY{n}{C\PYZus{}test}\PY{p}{[}\PY{n+nb}{int}\PY{p}{(}\PY{p}{(}\PY{n}{c}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}\PY{o}{/}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{]}\PY{p}{,}\PY{n}{gam\PYZus{}test}\PY{p}{[}\PY{n+nb}{int}\PY{p}{(}\PY{p}{(}\PY{n}{c}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}\PY{o}{\PYZpc{}}\PY{k}{3})]))
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
The maximum accuracy: 90.133\%
The corresponding best C and gamma: C=10, gamma=0.01

    \end{Verbatim}

    \hypertarget{using-gridsearchcv-optional-section}{%
\subsection{\texorpdfstring{Using \texttt{GridSearchCV} (Optional
Section)}{Using GridSearchCV (Optional Section)}}\label{using-gridsearchcv-optional-section}}

In the previous section, you would have likely used \texttt{for-loops}
to search over the different \texttt{C} and \texttt{gamma} values. Since
this type of parameter search is so commonly used, \texttt{sklearn} has
an excellent method \texttt{GridSearchCV} that can perform all the
operations for you. In this lab, \texttt{GridSearchCV} is not that
useful. But, once you get to more complex parameter searches, the
\texttt{GridSearchCV} method can save you writing a lot of code.
Importantly, \texttt{GridSearchCV} supports parallelization so that fits
with different parameters can be fit at the same time. In this optional
section, we will show how to use this method.

\textbf{You do not have to do this section, if you did the previous
section}.

    The \texttt{GridSearchCV} method does the train-test split in addition
to the parameter search. In this case, you have already a fixed
train-test split. So, you first need to combine the train and test data
back into a single dataset.

Create arrays \texttt{X} and \texttt{y} from \texttt{Xtr1},
\texttt{Xts1}, \texttt{ytr} and \texttt{yts}. Use \texttt{np.vstack} and
\texttt{np.hstack}.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}21}]:} \PY{c+c1}{\PYZsh{} TODO:  Create combined trained and test data X and y.}
         \PY{c+c1}{\PYZsh{} X = ...}
         \PY{c+c1}{\PYZsh{} y = ...}
\end{Verbatim}


    Normally, \texttt{GridSearchCV} will do \(K\)-fold validation and
automatically split the data into training and test in each fold. But,
in this case, we want it to perform only one fold with a specific
train-test split. To do this, we need to do the following: * Create a
vector \texttt{test\_fold} where \texttt{test\_fold{[}i{]}\ =\ -1} for
the samples \texttt{i} in the training data (this indicates that they
should not be used as test data in any fold) and
\texttt{test\_fold{[}i{]}\ =\ 0} for the samples \texttt{i} in the test
data (this indicates that they should be as test data in fold 0). * Call
the method
\texttt{ps\ =\ sklearn.model\_selection.PredefinedSplit(test\_fold)} to
create a predefined test split object.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}22}]:} \PY{c+c1}{\PYZsh{} TODO:  Create a pre\PYZhy{}defined test split object }
         \PY{c+c1}{\PYZsh{} import sklearn.model\PYZus{}selection}
         \PY{c+c1}{\PYZsh{} test\PYZus{}fold = ...}
         \PY{c+c1}{\PYZsh{} ps = sklearn.model\PYZus{}selection.PredefinedSplit(test\PYZus{}fold)}
\end{Verbatim}


    Next, read about the \texttt{GridSearchCV} method to set up a classifier
that includes searching over the parameter grid.\\
* For the \texttt{param\_grid} parameter, you will want to create a
dictionary to search over \texttt{C} and \texttt{gamma}. You will also
need to select the \texttt{kernel} parameter. * Set \texttt{cv\ =\ ps}
to use the fixed train-test split. * Set \texttt{verbose=10} to monitor
the progress

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}23}]:} \PY{c+c1}{\PYZsh{} TODO:  Create a GridSearchCV classifier}
         \PY{c+c1}{\PYZsh{} clf = ...}
\end{Verbatim}


    Fit the classifier using the \texttt{fit} method. The fit method will
now search over all the parameters. This will take about 30 minutes.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}24}]:} \PY{c+c1}{\PYZsh{} TODO: Fit the classifier}
\end{Verbatim}


    Print the \texttt{best\_score\_} and \texttt{best\_params\_} attributes
of the classifier to find the best score and parameters

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}25}]:} \PY{c+c1}{\PYZsh{} TODO:  Print the best parameter and score of the classifier}
\end{Verbatim}


    Finally, you can print the test and train score from the
\texttt{cv\_results\_{[}\textquotesingle{}mean\_test\_score\textquotesingle{}{]}}
and
\texttt{cv\_results\_{[}\textquotesingle{}mean\_train\_score\textquotesingle{}{]}}.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}26}]:} \PY{c+c1}{\PYZsh{} TODO:  Print the mean test score for each parameter value.}
\end{Verbatim}



    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
